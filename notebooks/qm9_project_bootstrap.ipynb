{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# CELL 0 - Mount Drive and install PyG + deps from saved wheels\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "WHEEL_DIR = \"/content/drive/MyDrive/PyG_wheels_torch29_cu126\"\n",
        "!pip install {WHEEL_DIR}/*.whl\n",
        "\n",
        "import torch, torch_geometric\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"torch_geometric:\", torch_geometric.__version__)\n",
        "from torch_geometric.datasets import QM9\n",
        "print(\"QM9 import OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaAcmCvdnKXM",
        "outputId": "4b4b1282-e70d-454e-ab98-a4a2066808c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/aiohappyeyeballs-2.6.1-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/aiosignal-1.4.0-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/attrs-25.4.0-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/certifi-2025.11.12-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/fsspec-2025.10.0-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/idna-3.11-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/jinja2-3.1.6-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/pyparsing-3.2.5-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/requests-2.32.5-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/torch_cluster-1.6.3-cp312-cp312-linux_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/torch_geometric-2.7.0-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/torch_spline_conv-1.2.2-cp312-cp312-linux_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/tqdm-4.67.1-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/typing_extensions-4.15.0-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/urllib3-2.5.0-py3-none-any.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
            "Processing ./drive/MyDrive/PyG_wheels_torch29_cu126/yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl\n",
            "aiohappyeyeballs is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "aiohttp is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "aiosignal is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "attrs is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "certifi is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "charset-normalizer is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "frozenlist is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "fsspec is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "idna is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "jinja2 is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "markupsafe is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "multidict is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "numpy is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "propcache is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "psutil is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "pyparsing is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "requests is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "scipy is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "torch-cluster is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "torch-geometric is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "torch-scatter is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "torch-sparse is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "torch-spline-conv is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "tqdm is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "typing-extensions is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "urllib3 is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "xxhash is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "yarl is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "torch: 2.9.0+cu126\n",
            "torch_geometric: 2.7.0\n",
            "QM9 import OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1 - Clone (or refresh) QM9_project repo\n",
        "\n",
        "%cd /content\n",
        "!test -d QM9_project || git clone https://github.com/zeugirdoR/QM9_project.git\n",
        "%cd QM9_project\n",
        "!git pull\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYCCpGIYnWub",
        "outputId": "a4161e45-5852-466e-cee6-44e704d162e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'QM9_project'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 37 (delta 6), reused 33 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (37/37), 21.63 KiB | 21.63 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "/content/QM9_project\n",
            "Already up to date.\n",
            "bootstrapwheels.py  how2git.txt\t\t\trequirements.txt\n",
            "data\t\t    models\t\t\tsetup_pyg_wheels.py\n",
            "env\t\t    newColabenv.py\t\ttrain_qm9_baseline.py\n",
            "eval_qm9_legacy.py  orig_train_qm9_baseline.py\n",
            "fastboot.sh\t    README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2 - Warm QM9 test with tiny model (sanity check)\n",
        "\n",
        "%cd /content/QM9_project\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "dataset = QM9(root=\"data/qm9\")\n",
        "print(f\"Total graphs: {len(dataset)}\")\n",
        "\n",
        "n_train = 109_898\n",
        "n_val   = 13_083\n",
        "n_test  = 7_850\n",
        "\n",
        "train_dataset = dataset[:n_train]\n",
        "val_dataset   = dataset[n_train:n_train + n_val]\n",
        "test_dataset  = dataset[n_train + n_val:]\n",
        "\n",
        "print(f\"Train/Val/Test = {len(train_dataset)}, {len(val_dataset)}, {len(test_dataset)}\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "class WarmTestNet(nn.Module):\n",
        "    def __init__(self, in_channels, hidden=64):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(in_channels, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = torch.cat([data.x, data.pos], dim=-1)\n",
        "        batch = data.batch\n",
        "        num_graphs = int(batch.max()) + 1\n",
        "\n",
        "        graph_sum = torch.zeros(num_graphs, x.size(-1), device=x.device)\n",
        "        graph_count = torch.zeros(num_graphs, 1, device=x.device)\n",
        "\n",
        "        graph_sum.index_add_(0, batch, x)\n",
        "        graph_count.index_add_(0, batch, torch.ones_like(x[:, :1]))\n",
        "\n",
        "        graph_mean = graph_sum / graph_count\n",
        "        out = self.mlp(graph_mean)\n",
        "        return out.squeeze(-1)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "in_channels = batch.x.size(-1) + batch.pos.size(-1)\n",
        "print(\"In channels (x + pos):\", in_channels)\n",
        "\n",
        "model = WarmTestNet(in_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "batch = batch.to(device)\n",
        "target_idx = 12  # U0\n",
        "y = batch.y[:, target_idx]\n",
        "\n",
        "pred = model(batch)\n",
        "print(\"pred shape:\", pred.shape, \"target shape:\", y.shape)\n",
        "\n",
        "loss = loss_fn(pred, y)\n",
        "print(\"Warm test loss:\", loss.item())\n",
        "\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(\"✅ Warm test forward + backward pass completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEDZ-tQEnb2k",
        "outputId": "486e3344-3d02-4522-d223-3491ea21cf26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/QM9_project\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.pyg.org/datasets/qm9_v3.zip\n",
            "Extracting data/qm9/raw/qm9_v3.zip\n",
            "Processing...\n",
            "Using a pre-processed version of the dataset. Please install 'rdkit' to alternatively process the raw data.\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total graphs: 130831\n",
            "Train/Val/Test = 109898, 13083, 7850\n",
            "In channels (x + pos): 14\n",
            "pred shape: torch.Size([64]) target shape: torch.Size([64])\n",
            "Warm test loss: 74.15080261230469\n",
            "✅ Warm test forward + backward pass completed.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}